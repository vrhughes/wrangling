{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
      "metadata": {
        "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
      },
      "source": [
        "# Assignment: Data Wrangling\n",
        "## `! git clone https://github.com/DS3001/wrangling`\n",
        "## Do Q2, and one of Q1 or Q3."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/DS3001/wrangling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8zSqXB4yQcI",
        "outputId": "119d76e1-1772-4a6b-f833-883773977f64"
      },
      "id": "B8zSqXB4yQcI",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'wrangling' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5735a4d4-8be8-433a-a351-70eb8002e632",
      "metadata": {
        "id": "5735a4d4-8be8-433a-a351-70eb8002e632"
      },
      "source": [
        "**Q1.** Open the \"tidy_data.pdf\" document in the repo, which is a paper called Tidy Data by Hadley Wickham.\n",
        "\n",
        "  1. Read the abstract. What is this paper about?\n",
        "  2. Read the introduction. What is the \"tidy data standard\" intended to accomplish?\n",
        "  3. Read the intro to section 2. What does this sentence mean: \"Like families, tidy datasets are all alike but every messy dataset is messy in its own way.\" What does this sentence mean: \"For a given dataset, itâ€™s usually easy to figure out what are observations and what are variables, but it is surprisingly difficult to precisely define variables and observations in general.\"\n",
        "  4. Read Section 2.2. How does Wickham define values, variables, and observations?\n",
        "  5. How is \"Tidy Data\" defined in section 2.3?\n",
        "  6. Read the intro to Section 3 and Section 3.1. What are the 5 most common problems with messy datasets? Why are the data in Table 4 messy? What is \"melting\" a dataset?\n",
        "  7. Why, specifically, is table 11 messy but table 12 tidy and \"molten\"?\n",
        "  8. Read Section 6. What is the \"chicken-and-egg\" problem with focusing on tidy data? What does Wickham hope happens in the future with further work on the subject of data wrangling?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "o-cOdYj4zZlO"
      },
      "id": "o-cOdYj4zZlO",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072",
      "metadata": {
        "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
      },
      "source": [
        "**Q2.** This question provides some practice cleaning variables which have common problems.\n",
        "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
        "2. Categorical variable: For the `./data/sharks.csv` data covered in the lecture, clean the \"Type\" variable as well as you can, and explain the choices you make.\n",
        "3. Dummy variable: For the pretrial data covered in the lecture, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`.\n",
        "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1\n",
        "# loading and viewing data\n",
        "data1 = pd.read_csv('https://raw.githubusercontent.com/vrhughes/wrangling/main/assignment/data/airbnb_hw.csv', low_memory = False)\n",
        "print(data1.shape, '\\n') # dimensions\n",
        "print(data1.dtypes, '\\n') # types\n",
        "print(data1.columns, '\\n') # col names\n",
        "data1.head()"
      ],
      "metadata": {
        "id": "CODJ2J592Avj"
      },
      "id": "CODJ2J592Avj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1\n",
        "# assign variable name and look for unique values to see problems easier\n",
        "price = data1['Price']\n",
        "print(price.unique(), '\\n')\n",
        "\n",
        "# reassign getting rid of commas\n",
        "price = price.str.replace(',', '')\n",
        "print(price.unique(), '\\n')\n",
        "\n",
        "# find out type of price, if it is not price then will need to coerce\n",
        "print('Before coercion: \\n', price.describe(), '\\n')\n",
        "\n",
        "# coerce price to numeric from object type\n",
        "price = pd.to_numeric(price, errors = 'coerce')\n",
        "\n",
        "# see after coercion and check again for unique values\n",
        "print('After coercion: \\n', price.describe(), '\\n', price.unique(), '\\n')\n",
        "\n",
        "# missing dummy to see if any values are missing\n",
        "data1['price_missing'] = price.isnull()\n",
        "print('Missing: \\n', sum(data1['price_missing']), '\\n')\n",
        "\n",
        "# Since no values were missing I decided this data was cleaned to the best of my ability"
      ],
      "metadata": {
        "id": "izR9IYyD3WkR"
      },
      "id": "izR9IYyD3WkR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2\n",
        "# loading in and viewing data\n",
        "sharks = pd.read_csv('https://raw.githubusercontent.com/vrhughes/wrangling/main/assignment/data/sharks.csv', low_memory = False)\n",
        "print(sharks.shape, '\\n') # dimensions\n",
        "print(sharks.dtypes, '\\n') # types\n",
        "sharks.head()\n",
        "\n",
        "# getting a better idea of 'Type' values\n",
        "print(sharks['Type'].unique(), '\\n')\n",
        "print(sharks['Type'].value_counts(), '\\n')\n",
        "\n",
        "# consolidate 'Type' categories\n",
        "sharks['Type'] = sharks['Type'].replace(['Sea Disaster', 'Boat', 'Boating', 'Boatomg'], 'Watercraft')\n",
        "sharks['Type'] = sharks['Type'].replace(['Invalid', 'Questionable', 'Unconfirmed', 'Unverified', 'Under investigation'], np.nan)\n",
        "\n",
        "# visualize consolidation\n",
        "print(sharks['Type'].value_counts(), '\\n')\n"
      ],
      "metadata": {
        "id": "2Cy6V4_Q9FKQ"
      },
      "id": "2Cy6V4_Q9FKQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3\n",
        "# load data and take a peek\n",
        "url = 'http://www.vcsc.virginia.gov/pretrialdataproject/October%202017%20Cohort_Virginia%20Pretrial%20Data%20Project_Deidentified%20FINAL%20Update_10272021.csv'\n",
        "d3 = pd.read_csv(url, low_memory = False) # Pandas downloads and loads the .csv file for you\n",
        "d3.head()"
      ],
      "metadata": {
        "id": "TBa5uKmKGy8X"
      },
      "id": "TBa5uKmKGy8X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3\n",
        "# making a dummy variable\n",
        "released = d3['WhetherDefendantWasReleasedPretrial']\n",
        "\n",
        "# viewing released data\n",
        "print(released.unique(), '\\n')\n",
        "print(released.value_counts(), '\\n')\n",
        "print(released.describe(), '\\n')\n",
        "\n",
        "# Replacing 9s with nan\n",
        "released = released.replace(9, np.nan)\n",
        "print(released.unique(), '\\n')\n",
        "print(released.value_counts(), '\\n')\n",
        "print(released.describe(), '\\n')\n",
        "\n",
        "# Reinserting the cleaned data\n",
        "d3['WhetherDefendantWasReleasedPretrial'] = released\n",
        "del released # getting rid of dummy var\n",
        "d3['WhetherDefendantWasReleasedPretrial'].value_counts() # Checking that everything worked"
      ],
      "metadata": {
        "id": "-kptNKcoSCFL"
      },
      "id": "-kptNKcoSCFL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 4\n",
        "# making dummy variables and viewing them\n",
        "time = d3['ImposedSentenceAllChargeInContactEvent']\n",
        "category = d3['SentenceTypeAllChargesAtConvictionInContactEvent']\n",
        "print(time.unique(), '\\n')\n",
        "print(category.unique(), '\\n')\n",
        "print(time.value_counts(), '\\n')\n",
        "print(category.value_counts(), '\\n')\n",
        "\n",
        "# from observing the data and codebook\n",
        "# category: 0 = probation/no incarceration, 1 = jail up to 12 months, 2 = prison (1+ yrs), 4 = dismissed, deferred, 9 = not applicable/unknown\n",
        "# time: some data are ' '\n",
        "time = pd.to_numeric(time, errors = 'coerce')\n",
        "\n",
        "# see how many vals are missing\n",
        "missing = time.isnull()\n",
        "print(sum(missing), '\\n')\n",
        "\n",
        "time = time.mask(category == 9, np.nan)\n",
        "time = time.mask(category == 4, 0)\n",
        "\n",
        "# see how many vals are missing still\n",
        "missing = time.isnull()\n",
        "print(sum(missing), '\\n')\n",
        "\n",
        "# reinstate time into dataframe\n",
        "d3['ImposedSentenceAllChargeInContactEvent'] = time\n",
        "del time, category\n"
      ],
      "metadata": {
        "id": "iHjoBto_To02"
      },
      "id": "iHjoBto_To02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5",
      "metadata": {
        "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5"
      },
      "source": [
        "**Q3.** Many important datasets contain a race variable, typically limited to a handful of values often including Black, White, Asian, Latino, and Indigenous. This question looks at data gathering efforts on this variable by the U.S. Federal government.\n",
        "\n",
        "1. How did the most recent US Census gather data on race?\n",
        "2. Why do we gather these data? What role do these kinds of data play in politics and society? Why does data quality matter?\n",
        "3. Please provide a constructive criticism of how the Census was conducted: What was done well? What do you think was missing? How should future large scale surveys be adjusted to best reflect the diversity of the population? Could some of the Census' good practices be adopted more widely to gather richer and more useful data?\n",
        "4. How did the Census gather data on sex and gender? Please provide a similar constructive criticism of their practices.\n",
        "5. When it comes to cleaning data, what concerns do you have about protected characteristics like sex, gender, sexual identity, or race? What challenges can you imagine arising when there are missing values? What good or bad practices might people adopt, and why?\n",
        "6. Suppose someone invented an algorithm to impute values for protected characteristics like race, gender, sex, or sexuality. What kinds of concerns would you have?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I looked at ACS Demographic and Housing Estimates table.\n",
        "1. Race had the option to choose one or more. There were general categories, like white and black, which had further information on what should fall under that category (Irish, Haitian, Navajo). Additionally, there was a separate section on hispanic/latino/spanish origin which asked which country you had origins in.\n",
        "2. We gather these data because it is important to accurately understand the state of the country and its citizens. These data can help policy creation and change as well as give insights on the economy. Quality matters because skewed or inaccurate data leads to incorrect understandings of the countries needs and the government has a responsibility to do the census right so everyone can get the true information.\n",
        "3. There didn't seem to be a whole lot missing, the only thing I can really think of is sexuality but I am not sure if I would recommend that it should be included? Maybe it could be optional because it feels somewhat intrusive. I think something that would be cool to add is how many generations your family has been here (whoever you can trace back most recently to being an immigrant), or if you are first gen what country you came from. I think that could give us a better idea of the countries migration \"patterns\" if you will.\n",
        "4. The ACS said to only choose one, male or female. There was no question about sexuality, unless you count the option to say a person other than person 1 was person 1's same sex partner or spouse. As I said above, I find it somewhat odd to think that the government would want a written record of how one identifies their sexuality. I am sure it would just be used for knowledge purposes, but it does seem a bit intrusive to me. I think making it an optional portion at the end could be a happy medium? I also think that because new terminology is always being used it might also just be easier to put straight or not, I don't think finding out if someone is bisexual versus lesbian would really be beneficial so I would just not take it that far.\n",
        "5. As I said in question 4, I think people are constantly changing certain terminologies in how they identify (and the public terminology also changes over time! The term \"colored\" used to be popular, but is now seen as old-fashioned and out-dated), so I don't think you could ever get consistent data for these topics because someone will always feel like there isn't a box they fall in. When it comes to missing data these categories I think you can only leave it as missing, you can't really guess or fill it in because of how subjective identity is. Maybe they no longer have connections to their heritage and don't want to identify as what they put last time. I can imagine it would be frustrating because then you feel like you aren't getting an accurate full picture, but I also think that you'll never get the full picture. Instead you can just add it to an unanswered section so if it is miniscule you can say it wouldn't have much affect, and if it is larger you can keep that in mind when you start processing the whole data set.\n",
        "6. It seems like I kind of just accidentally covered that above, so I will repeat a little bit. I think imputing is a bad idea because people's perception of their identity changes all the time (especially with sexuality), so having some program do it really just doesn't make sense to me. Also I would wonder what the computer is basing this on, past responses? Regardless, it just seems dumb to me because it seems like a sure way to misrepresent a lot of the population instead of letting them fill it out themselves. I understand that missing data is annoying but I think it diminishes the datas integrity if you try and fill it in. Instead I would just leave it blank and how that the blanks do not make up a significant portion of the data."
      ],
      "metadata": {
        "id": "64KsJwysazEa"
      },
      "id": "64KsJwysazEa"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}